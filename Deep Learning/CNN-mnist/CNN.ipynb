{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32aaf52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\negovin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9514 - loss: 0.1642 - val_accuracy: 0.9838 - val_loss: 0.0553\n",
      "Epoch 2/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9842 - loss: 0.0503 - val_accuracy: 0.9867 - val_loss: 0.0499\n",
      "Epoch 3/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9894 - loss: 0.0346 - val_accuracy: 0.9867 - val_loss: 0.0436\n",
      "Epoch 4/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.9923 - loss: 0.0252 - val_accuracy: 0.9895 - val_loss: 0.0405\n",
      "Epoch 5/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 19ms/step - accuracy: 0.9933 - loss: 0.0195 - val_accuracy: 0.9917 - val_loss: 0.0345\n",
      "Epoch 6/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.9915 - val_loss: 0.0352\n",
      "Epoch 7/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9956 - loss: 0.0127 - val_accuracy: 0.9875 - val_loss: 0.0470\n",
      "Epoch 8/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9969 - loss: 0.0097 - val_accuracy: 0.9917 - val_loss: 0.0361\n",
      "Epoch 9/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9970 - loss: 0.0086 - val_accuracy: 0.9910 - val_loss: 0.0406\n",
      "Epoch 10/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9912 - val_loss: 0.0491\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0376\n",
      "Test accuracy: 98.93%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "# Reshape to (samples, height, width, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c1fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "Predicted digit: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on a sample image\n",
    "import numpy as np\n",
    "\n",
    "sample_image = x_test[35].reshape(1,28,28,1)\n",
    "prediction = model.predict(sample_image)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(\"Predicted digit:\", predicted_class)\n",
    "\n",
    "# Display the sample image\n",
    "plt.imshow(x_test[3500].reshape(28,28), cmap='gray')\n",
    "plt.title(f\"Predicted digit: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8153349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as mnist_cnn_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mnist_cnn_model.h5\")\n",
    "print(\"Model saved as mnist_cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5db4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"mnist_cnn_model.h5\")\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01f6741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"mnist_cnn_model.h5\")\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41200950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"mnist_cnn_model.h5\")\n",
    "\n",
    "# Load PNG image\n",
    "img = image.load_img(\n",
    "    \"five.png\",\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(28, 28)\n",
    ")\n",
    "\n",
    "# Convert to array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Normalize and reshape\n",
    "img_array = img_array / 255.0\n",
    "img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "# Display result\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f\"Predicted digit: {predicted_digit}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74246edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
