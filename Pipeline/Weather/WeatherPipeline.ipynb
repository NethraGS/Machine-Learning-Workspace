{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d23be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Dropped 0 rows with NaN in target 'temperature_c'. Remaining: 10000\n",
      "[Info] Model trained on 10000 rows.\n",
      "Predicted Temperature (°C): 61.15\n",
      "Interpretation: Hot day.\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "# === Config ===\n",
    "DATA_PATH = \"weather_linear_regression_10000.csv\"\n",
    "TARGET = \"temperature_c\"\n",
    " \n",
    "DATE_COL = \"date\"\n",
    "NUMERIC_COLS = [\n",
    "    \"humidity_percent\",\n",
    "    \"pressure_hpa\",\n",
    "    \"wind_speed_kmph\",\n",
    "    \"cloud_cover_percent\",\n",
    "    \"rainfall_mm\",\n",
    "    \"sunshine_hours\",\n",
    "    # 'temperature_c' must be excluded from features since it's the target\n",
    "]\n",
    " \n",
    "# === Custom Date Transformer (robust to pandas versions) ===\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms a pandas datetime Series into engineered time features:\n",
    "    year, month, day, dayofweek, dayofyear, and cyclic encodings.\n",
    "    Robust to DataFrame/ndarray inputs and missing dates.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_names_ = [\n",
    "            \"year\", \"month\", \"day\", \"dayofweek\", \"dayofyear\",\n",
    "            \"month_sin\", \"month_cos\", \"doy_sin\", \"doy_cos\"\n",
    "        ]\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X):\n",
    "        # Normalize input to a Series of datetime\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            ser = pd.to_datetime(X.iloc[:, 0], errors=\"coerce\")\n",
    "        else:\n",
    "            ser = pd.to_datetime(pd.Series(X[:, 0]), errors=\"coerce\")\n",
    " \n",
    "        ser = pd.Series(ser)  # ensure Series\n",
    "        if ser.isna().all():\n",
    "            ser = pd.to_datetime(pd.Series([\"2000-01-01\"] * len(ser)))\n",
    "        else:\n",
    "            ser = ser.ffill().bfill()\n",
    " \n",
    "        year = ser.dt.year.astype(float)\n",
    "        month = ser.dt.month.astype(float)\n",
    "        day = ser.dt.day.astype(float)\n",
    "        dayofweek = ser.dt.dayofweek.astype(float)\n",
    "        dayofyear = ser.dt.dayofyear.astype(float)\n",
    " \n",
    "        # Cyclic encodings\n",
    "        month_sin = np.sin(2 * np.pi * (month / 12.0))\n",
    "        month_cos = np.cos(2 * np.pi * (month / 12.0))\n",
    "        doy_sin = np.sin(2 * np.pi * (dayofyear / 365.25))\n",
    "        doy_cos = np.cos(2 * np.pi * (dayofyear / 365.25))\n",
    " \n",
    "        features = np.vstack([\n",
    "            year, month, day, dayofweek, dayofyear,\n",
    "            month_sin, month_cos, doy_sin, doy_cos\n",
    "        ]).T\n",
    "        return features\n",
    " \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_)\n",
    " \n",
    "# === Load data ===\n",
    "df = pd.read_csv(DATA_PATH)\n",
    " \n",
    "# Basic schema checks\n",
    "if DATE_COL not in df.columns:\n",
    "    raise ValueError(f\"Column '{DATE_COL}' not found in dataset columns: {df.columns.tolist()}\")\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"Target '{TARGET}' not found in dataset columns: {df.columns.tolist()}\")\n",
    " \n",
    "# Ensure all expected feature columns exist\n",
    "missing_feats = [c for c in NUMERIC_COLS if c not in df.columns]\n",
    "if missing_feats:\n",
    "    raise ValueError(f\"Missing expected numeric feature columns: {missing_feats}\")\n",
    " \n",
    "# --- Clean types ---\n",
    "# Coerce target to numeric and drop rows with missing target\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[TARGET]).copy()\n",
    "print(f\"[Info] Dropped {before - len(df)} rows with NaN in target '{TARGET}'. Remaining: {len(df)}\")\n",
    " \n",
    "# Coerce numeric feature columns to numeric (bad strings -> NaN -> imputed later)\n",
    "for col in NUMERIC_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    " \n",
    "# === Build X, y ===\n",
    "X = df[[DATE_COL] + NUMERIC_COLS].copy()\n",
    "y = df[TARGET].copy()\n",
    " \n",
    "# === Build pipelines ===\n",
    "date_pipeline = Pipeline(steps=[\n",
    "    (\"date_features\", DateFeatureExtractor()),\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    " \n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    " \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"date\", date_pipeline, [DATE_COL]),\n",
    "        (\"num\", numeric_pipeline, NUMERIC_COLS)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    " \n",
    "linreg_model = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    " \n",
    "# === Fit model ===\n",
    "linreg_model.fit(X, y)\n",
    "print(\"[Info] Model trained on\", len(X), \"rows.\")\n",
    " \n",
    "# === Single-row prediction (edit values as needed) ===\n",
    "test_data = {\n",
    "    \"date\": \"2015-01-03\",        # the pipeline parses this\n",
    "    \"humidity_percent\": 72.5,\n",
    "    \"pressure_hpa\": 1005.1,\n",
    "    \"wind_speed_kmph\": 12.3,\n",
    "    \"cloud_cover_percent\": 58.0,\n",
    "    \"rainfall_mm\": 2.4,\n",
    "    \"sunshine_hours\": 6.2,\n",
    "}\n",
    "test_df = pd.DataFrame([test_data])\n",
    " \n",
    "prediction = linreg_model.predict(test_df)\n",
    "pred_value = float(prediction[0])\n",
    "print(\"Predicted Temperature (°C):\", round(pred_value, 2))\n",
    " \n",
    "# Optional quick interpretation\n",
    "if pred_value < 20:\n",
    "    print(\"Interpretation: Rather cool day.\")\n",
    "elif pred_value < 30:\n",
    "    print(\"Interpretation: Mild to warm.\")\n",
    "else:\n",
    "    print(\"Interpretation: Hot day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377fa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
